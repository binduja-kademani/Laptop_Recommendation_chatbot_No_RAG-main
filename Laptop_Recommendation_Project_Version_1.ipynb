{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.8.3)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (0.6.10)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (2.21.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (2.149.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (2.35.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (5.28.2)\n",
      "Requirement already satisfied: pydantic in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (2.9.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.24.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core->google-generativeai) (1.65.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic->google-generativeai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sandy\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.66.2)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.66.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python312\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.54.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sandy\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\sandy\\AppData\\Roaming\\Python\\Python312\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install google-generativeai\n",
    "%pip install openai\n",
    "import google.generativeai as genai\n",
    "import openai\n",
    "import getpass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the model you want to use: openai or gemini\n",
      "You selected:  openai\n",
      "Enter your Gemini/openai API key: Please Note this is a demo version, only Gemini and openai is currently supported. Input is hidden\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter the model you want to use: openai or gemini\")\n",
    "model_name = input()\n",
    "print(\"You selected: \", model_name)\n",
    "print(\"Enter your Gemini/openai API key: Please Note this is a demo version, only Gemini and openai is currently supported. Input is hidden\")\n",
    "API_KEY = getpass.getpass()\n",
    "#model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "#response = model.generate_content(\"Write a story about a magic backpack\")\n",
    "#print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_chatbot_comm(user_input, history=[]):\n",
    "    genai.configure(api_key=API_KEY)\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    chat = model.start_chat(\n",
    "    history = history\n",
    "    )\n",
    "    generation_config = {\n",
    "        \"temperature\": 0.1  # Adjust temperature for more deterministic (lower) or more creative (higher) responses\n",
    "    }\n",
    "    response = chat.send_message(user_input, generation_config=generation_config)\n",
    "    history.append({\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [{\"text\": user_input}]\n",
    "    })\n",
    "    history.append({\n",
    "        \"role\": \"model\",\n",
    "        \"parts\": [{\"text\": response.text}]\n",
    "    })\n",
    "    return response.text, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_chatbot_comm(user_input, history=[]):\n",
    "    openai.api_key = API_KEY\n",
    "    history.append({\n",
    "        \"role\": \"user\",\n",
    "        'content': user_input\n",
    "    })\n",
    "    \n",
    "    \n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\", \n",
    "        temperature=0.1,\n",
    "        messages=history\n",
    "    )\n",
    "    history.append({\n",
    "        \"role\": \"assistant\",\n",
    "        'content': response.choices[0].message.content\n",
    "    })\n",
    "    return response.choices[0].message.content, history\n",
    "\n",
    "\n",
    "\n",
    "# response, history = openai_chatbot_comm(\"Hello\")\n",
    "# print(response)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Laptop Recommendation Chatbot! Please Note this is a demo version. \n",
      "Bot:  Hello! I'm here to help you find the perfect laptop for your needs. What specific requirements or preferences do you have in mind? Are you looking for something for gaming, work, school, or general use? Let me know how I can assist you!\n",
      "You:  I am looking for a gaming laptop\n",
      "bot: Great! Gaming laptops typically require a good budget and strong specifications. What is your budget in INR? \n",
      "--------------------\n",
      "user: My Budget is 60000\n",
      "bot: Thank you! Now, how intense do you expect your gaming experience to be? Would you say the GPU intensity is Low, Medium, or High? \n",
      "--------------------\n",
      "user: I am planning on playing High FPS Games\n",
      "bot: Got it! So we'll categorize the GPU intensity as High. Next, how do you plan to use the laptop in terms of multitasking? Would you say your multitasking needs are Low, Medium, or High? \n",
      "--------------------\n",
      "user: I only plan on playing games\n",
      "bot: Understood! We'll consider your multitasking needs as Low. Now, how important is portability for you? Would you say it's Low, Medium, or High? \n",
      "--------------------\n",
      "user: I am not planning on taking my Laptop outside\n",
      "bot: Thanks for the clarification! We'll categorize portability as Low. Next, how important is processing speed for your gaming experience? Would you rate it as Low, Medium, or High? \n",
      "--------------------\n",
      "user: I want my Games running as smooth as possible\n",
      "bot: Great! We'll classify processing speed as High. Lastly, how important is display quality for your gaming experience? Would you say it's Low, Medium, or High? \n",
      "--------------------\n",
      "user: I want my Games looking as good as possible.\n",
      "bot: Thank you for that! We'll categorize display quality as High. Here’s a summary of the information you've provided:\n",
      "--------------------\n",
      "Thank you for that! We'll categorize display quality as High. Here’s a summary of the information you've provided:\n",
      "bot: Based on your requirements, here are three great gaming laptop recommendations within your budget of 60,000 INR:\n",
      "\n",
      "1. **Acer Aspire 7**\n",
      "   - **Price:** Approximately 55,000 INR\n",
      "   - **Description:** The Acer Aspire 7 is equipped with an AMD Ryzen 5 processor and an NVIDIA GTX 1650 GPU, making it suitable for high FPS gaming. It features a 15.6-inch Full HD display, providing excellent visuals. With 8GB RAM (expandable) and a 512GB SSD, it offers smooth performance and quick load times.\n",
      "\n",
      "2. **HP Pavilion Gaming Laptop**\n",
      "   - **Price:** Approximately 59,000 INR\n",
      "   - **Description:** The HP Pavilion Gaming Laptop comes with an AMD Ryzen 5 processor and an NVIDIA GTX 1650 graphics card. It has a 15.6-inch Full HD display and a sleek design. With 8GB RAM and a 512GB SSD, it ensures a good balance of performance and storage for gaming.\n",
      "\n",
      "3. **Lenovo IdeaPad Gaming 3**\n",
      "   - **Price:** Approximately 58,000 INR\n",
      "   - **Description:** The Lenovo IdeaPad Gaming 3 features an AMD Ryzen 5 processor and an NVIDIA GTX 1650 GPU. It has a 15.6-inch Full HD display with a high refresh rate, enhancing your gaming experience. With 8GB RAM and a 512GB SSD, it provides solid performance for gaming and multitasking.\n",
      "\n",
      "These laptops should meet your gaming needs while staying within your budget. Let me know if you need more information or further assistance!\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "def chatbot_comm(user_input, model, history=[]):\n",
    "    if 'gemini' in model.lower():\n",
    "        response, history = gemini_chatbot_comm(user_input, history)\n",
    "        return response, history\n",
    "    elif 'openai' in model.lower():\n",
    "        response, history = openai_chatbot_comm(user_input, history)\n",
    "        return response, history\n",
    "\n",
    "    \n",
    "\n",
    "# Moderation is not working due to exceeded limit. Will implement later once billing is sorted.\n",
    "# def moderate_response(response):\n",
    "#     url = \"https://api.openai.com/v1/moderations\"\n",
    "#     from openai import OpenAI\n",
    "#     client=OpenAI(api_key=api_key)\n",
    "#     response = client.moderations.create(input=response)\n",
    "#     return response.results[0].flagged\n",
    "\n",
    "def collect_info(user_input, model, history=[]):\n",
    "    sys_message2 = \"\"\"\n",
    "    Remember to ask the questions one by one and wait for the user's response before asking the next question.\n",
    "    Keep asking them questions to understand their needs better. The Following data needs to be collected: \n",
    "    1. User's budget \n",
    "    2. GPU Intensity \n",
    "    3. Multitasking \n",
    "    4. Portability\n",
    "    5. Processing Speed\n",
    "    6. Display Quality\n",
    "    The Values for the above parameters should only be Low, Medium, High. Only Budget can be a number in INR. \n",
    "    You need to infer the values from the user's input as shown in the example below:\n",
    "    -- GPU Intensity : High\n",
    "    -- Multitasking : Medium\n",
    "    -- Portability : Low\n",
    "    -- Processing Speed : High\n",
    "    -- Display Quality : High\n",
    "    -- Budget : 50000\n",
    "    Keep asking questions until you have all the information you need. \n",
    "    in the response, do not include the above instructions or response.\n",
    "    If 'Not Done', continue asking questions.\n",
    "    if 'Done', display the collected information in the above format\n",
    "    Mandatorily respond with 'Done' or 'Not Done' after the response.\n",
    "    \"\"\"\n",
    "    combined_input = f\"{sys_message2}\\n\\nUser: {user_input}\"\n",
    "    response, history = chatbot_comm(combined_input, model, history)\n",
    "    print(\"bot:\", response.split('\\n')[0])\n",
    "    print(\"-\"*20)\n",
    "    # user_input = input()\n",
    "    # print(\"user:\", user_input)\n",
    "    while 'Not Done' in response:\n",
    "        user_input = input()\n",
    "        print(\"user:\", user_input)\n",
    "        response, history = chatbot_comm(user_input, model, history)\n",
    "        print(\"bot:\", response.split('\\n')[0])\n",
    "        print(\"-\"*20)\n",
    "        #print('test 1 ------------------------------')\n",
    "    print(response.split('\\n')[0])\n",
    "    return response\n",
    "\n",
    "def display_info(data, model):\n",
    "    sys_message3 = f\"\"\"\n",
    "    You are the most intelligent laptop recommendation assistant.\n",
    "    The information collected from the user is as follows:\n",
    "    {data}\n",
    "    Use this information to recommend the best laptop for the user. Use your own training data to make recommendations. Its fine even if its not up-to-date.\n",
    "    respond with the name of the laptop, its price, and and a small description of the laptop.\n",
    "    Respond with three best recommendations.\n",
    "    \"\"\"\n",
    "    response, history = chatbot_comm(sys_message3, model)\n",
    "    print(\"bot:\", response)\n",
    "    print(\"-\"*20)\n",
    "    \n",
    "\n",
    "\n",
    "def initialize_conversation(model):\n",
    "    print(\"Welcome to the Laptop Recommendation Chatbot! Please Note this is a demo version. \")\n",
    "    sys_message = \"\"\"You are a helpful assistant that can help user choose the best laptop for their needs. \n",
    "    Greet the user and ask how you can help them.\n",
    "    \"\"\"\n",
    "    #combined_input = f\"{sys_message}\\n\\nUser: {user_input}\"\n",
    "    response, history = chatbot_comm(sys_message, model)\n",
    "    print(\"Bot: \", response)\n",
    "    user_input = input()\n",
    "    print(\"You: \", user_input)\n",
    "    #mod_resp = moderate_response(response)\n",
    "    #print(mod_resp)\n",
    "    # print(\"Bot: \", response)\n",
    "    # user_input = input()\n",
    "    # print(\"You: \", user_input)\n",
    "    # response, history = chatbot_comm(user_input, history)\n",
    "    # print(\"Bot: \", response)\n",
    "    data = collect_info(user_input, model, history) \n",
    "    display_info(data, model)\n",
    "    #print(history)\n",
    "\n",
    "\n",
    "initialize_conversation(model_name)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
